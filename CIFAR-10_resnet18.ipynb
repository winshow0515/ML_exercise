{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1ce4374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b735ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 1. 資料預處理 (Data Augmentation)\n",
    "# -------------------------\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),   # 隨機裁切 (增強泛化能力)\n",
    "    transforms.RandomHorizontalFlip(),      # 隨機水平翻轉\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010))  # 正規化 (CIFAR-10 常用均值/方差)\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d498da17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 2. 模型 (ResNet18)\n",
    "# -------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = torchvision.models.resnet18(num_classes=10)  # CIFAR-10 10 類\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83caa387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 3. Loss, Optimizer, Scheduler\n",
    "# -------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)  # 200 epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c3f01a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 4. 訓練 & 測試函數\n",
    "# -------------------------\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    total, correct, running_loss = 0, 0, 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    acc = 100.*correct/total\n",
    "    print(f\"Epoch [{epoch}] Train Loss: {running_loss/len(train_loader):.3f}, Acc: {acc:.2f}%\")\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    total, correct, test_loss = 0, 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    acc = 100.*correct/total\n",
    "    print(f\"Epoch [{epoch}] Test Loss: {test_loss/len(test_loader):.3f}, Acc: {acc:.2f}%\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889ed86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] Train Loss: 0.615, Acc: 78.98%\n",
      "Epoch [1] Test Loss: 0.808, Acc: 73.20%\n",
      "Epoch [2] Train Loss: 0.623, Acc: 78.78%\n",
      "Epoch [2] Test Loss: 0.722, Acc: 76.42%\n",
      "Epoch [3] Train Loss: 0.611, Acc: 79.02%\n",
      "Epoch [3] Test Loss: 0.833, Acc: 72.57%\n",
      "Epoch [4] Train Loss: 0.609, Acc: 79.13%\n",
      "Epoch [4] Test Loss: 0.922, Acc: 70.69%\n",
      "Epoch [5] Train Loss: 0.614, Acc: 78.92%\n",
      "Epoch [5] Test Loss: 0.705, Acc: 76.29%\n",
      "Epoch [6] Train Loss: 0.604, Acc: 79.52%\n",
      "Epoch [6] Test Loss: 0.731, Acc: 76.18%\n",
      "Epoch [7] Train Loss: 0.606, Acc: 79.32%\n",
      "Epoch [7] Test Loss: 0.631, Acc: 78.52%\n",
      "Epoch [8] Train Loss: 0.603, Acc: 79.43%\n",
      "Epoch [8] Test Loss: 0.756, Acc: 74.31%\n",
      "Epoch [9] Train Loss: 0.601, Acc: 79.27%\n",
      "Epoch [9] Test Loss: 0.675, Acc: 77.36%\n",
      "Epoch [10] Train Loss: 0.596, Acc: 79.57%\n",
      "Epoch [10] Test Loss: 0.625, Acc: 78.73%\n",
      "Epoch [11] Train Loss: 0.597, Acc: 79.65%\n",
      "Epoch [11] Test Loss: 0.685, Acc: 76.72%\n",
      "Epoch [12] Train Loss: 0.595, Acc: 79.67%\n",
      "Epoch [12] Test Loss: 0.687, Acc: 77.05%\n",
      "Epoch [13] Train Loss: 0.594, Acc: 79.52%\n",
      "Epoch [13] Test Loss: 0.652, Acc: 77.61%\n",
      "Epoch [14] Train Loss: 0.597, Acc: 79.55%\n",
      "Epoch [14] Test Loss: 0.707, Acc: 75.72%\n",
      "Epoch [15] Train Loss: 0.591, Acc: 79.83%\n",
      "Epoch [15] Test Loss: 0.682, Acc: 77.34%\n",
      "Epoch [16] Train Loss: 0.581, Acc: 80.25%\n",
      "Epoch [16] Test Loss: 0.749, Acc: 74.39%\n",
      "Epoch [17] Train Loss: 0.585, Acc: 79.93%\n",
      "Epoch [17] Test Loss: 0.663, Acc: 77.21%\n",
      "Epoch [18] Train Loss: 0.576, Acc: 80.43%\n",
      "Epoch [18] Test Loss: 0.655, Acc: 78.29%\n",
      "Epoch [19] Train Loss: 0.579, Acc: 80.20%\n",
      "Epoch [19] Test Loss: 0.719, Acc: 75.65%\n",
      "Epoch [20] Train Loss: 0.566, Acc: 80.61%\n",
      "Epoch [20] Test Loss: 0.618, Acc: 79.35%\n",
      "Epoch [21] Train Loss: 0.578, Acc: 80.20%\n",
      "Epoch [21] Test Loss: 0.641, Acc: 78.31%\n",
      "Epoch [22] Train Loss: 0.570, Acc: 80.35%\n",
      "Epoch [22] Test Loss: 0.625, Acc: 78.98%\n",
      "Epoch [23] Train Loss: 0.565, Acc: 80.49%\n",
      "Epoch [23] Test Loss: 0.647, Acc: 78.37%\n",
      "Epoch [24] Train Loss: 0.565, Acc: 80.62%\n",
      "Epoch [24] Test Loss: 0.596, Acc: 79.28%\n",
      "Epoch [25] Train Loss: 0.561, Acc: 80.88%\n",
      "Epoch [25] Test Loss: 0.635, Acc: 78.56%\n",
      "Epoch [26] Train Loss: 0.556, Acc: 80.85%\n",
      "Epoch [26] Test Loss: 0.705, Acc: 76.50%\n",
      "Epoch [27] Train Loss: 0.553, Acc: 81.07%\n",
      "Epoch [27] Test Loss: 0.668, Acc: 76.86%\n",
      "Epoch [28] Train Loss: 0.552, Acc: 81.04%\n",
      "Epoch [28] Test Loss: 0.636, Acc: 78.52%\n",
      "Epoch [29] Train Loss: 0.544, Acc: 81.44%\n",
      "Epoch [29] Test Loss: 0.624, Acc: 79.10%\n",
      "Epoch [30] Train Loss: 0.542, Acc: 81.38%\n",
      "Epoch [30] Test Loss: 0.723, Acc: 76.78%\n",
      "Epoch [31] Train Loss: 0.545, Acc: 81.32%\n",
      "Epoch [31] Test Loss: 0.640, Acc: 78.46%\n",
      "Epoch [32] Train Loss: 0.544, Acc: 81.44%\n",
      "Epoch [32] Test Loss: 0.578, Acc: 80.45%\n",
      "Epoch [33] Train Loss: 0.546, Acc: 81.57%\n",
      "Epoch [33] Test Loss: 0.628, Acc: 78.66%\n",
      "Epoch [34] Train Loss: 0.535, Acc: 81.78%\n",
      "Epoch [34] Test Loss: 0.739, Acc: 76.33%\n",
      "Epoch [35] Train Loss: 0.535, Acc: 81.72%\n",
      "Epoch [35] Test Loss: 0.636, Acc: 78.66%\n",
      "Epoch [36] Train Loss: 0.531, Acc: 81.87%\n",
      "Epoch [36] Test Loss: 0.688, Acc: 77.25%\n",
      "Epoch [37] Train Loss: 0.532, Acc: 81.97%\n",
      "Epoch [37] Test Loss: 0.636, Acc: 79.07%\n",
      "Epoch [38] Train Loss: 0.526, Acc: 82.05%\n",
      "Epoch [38] Test Loss: 0.610, Acc: 79.43%\n",
      "Epoch [39] Train Loss: 0.521, Acc: 82.07%\n",
      "Epoch [39] Test Loss: 0.637, Acc: 78.66%\n",
      "Epoch [40] Train Loss: 0.518, Acc: 82.26%\n",
      "Epoch [40] Test Loss: 0.580, Acc: 80.17%\n",
      "Epoch [41] Train Loss: 0.518, Acc: 82.29%\n",
      "Epoch [41] Test Loss: 0.570, Acc: 80.83%\n",
      "Epoch [42] Train Loss: 0.515, Acc: 82.32%\n",
      "Epoch [42] Test Loss: 0.662, Acc: 78.14%\n",
      "Epoch [43] Train Loss: 0.517, Acc: 82.36%\n",
      "Epoch [43] Test Loss: 0.694, Acc: 77.45%\n",
      "Epoch [44] Train Loss: 0.506, Acc: 82.81%\n",
      "Epoch [44] Test Loss: 0.631, Acc: 78.89%\n",
      "Epoch [45] Train Loss: 0.503, Acc: 82.85%\n",
      "Epoch [45] Test Loss: 0.574, Acc: 80.57%\n",
      "Epoch [46] Train Loss: 0.494, Acc: 82.99%\n",
      "Epoch [46] Test Loss: 0.608, Acc: 80.17%\n",
      "Epoch [47] Train Loss: 0.492, Acc: 83.12%\n",
      "Epoch [47] Test Loss: 0.587, Acc: 80.64%\n",
      "Epoch [48] Train Loss: 0.496, Acc: 83.04%\n",
      "Epoch [48] Test Loss: 0.618, Acc: 79.42%\n",
      "Epoch [49] Train Loss: 0.489, Acc: 83.25%\n",
      "Epoch [49] Test Loss: 0.633, Acc: 78.93%\n",
      "Epoch [50] Train Loss: 0.489, Acc: 83.08%\n",
      "Epoch [50] Test Loss: 0.610, Acc: 79.77%\n",
      "Epoch [51] Train Loss: 0.476, Acc: 83.68%\n",
      "Epoch [51] Test Loss: 0.592, Acc: 79.61%\n",
      "Epoch [52] Train Loss: 0.480, Acc: 83.45%\n",
      "Epoch [52] Test Loss: 0.598, Acc: 80.11%\n",
      "Epoch [53] Train Loss: 0.477, Acc: 83.51%\n",
      "Epoch [53] Test Loss: 0.597, Acc: 80.05%\n",
      "Epoch [54] Train Loss: 0.473, Acc: 83.69%\n",
      "Epoch [54] Test Loss: 0.590, Acc: 80.40%\n",
      "Epoch [55] Train Loss: 0.465, Acc: 83.96%\n",
      "Epoch [55] Test Loss: 0.599, Acc: 80.03%\n",
      "Epoch [56] Train Loss: 0.465, Acc: 84.18%\n",
      "Epoch [56] Test Loss: 0.560, Acc: 80.62%\n",
      "Epoch [57] Train Loss: 0.458, Acc: 84.21%\n",
      "Epoch [57] Test Loss: 0.552, Acc: 81.22%\n",
      "Epoch [58] Train Loss: 0.453, Acc: 84.28%\n",
      "Epoch [58] Test Loss: 0.628, Acc: 79.45%\n",
      "Epoch [59] Train Loss: 0.452, Acc: 84.47%\n",
      "Epoch [59] Test Loss: 0.559, Acc: 81.31%\n",
      "Epoch [60] Train Loss: 0.446, Acc: 84.73%\n",
      "Epoch [60] Test Loss: 0.574, Acc: 80.58%\n",
      "Epoch [61] Train Loss: 0.441, Acc: 84.73%\n",
      "Epoch [61] Test Loss: 0.605, Acc: 80.52%\n",
      "Epoch [62] Train Loss: 0.446, Acc: 84.43%\n",
      "Epoch [62] Test Loss: 0.599, Acc: 80.25%\n",
      "Epoch [63] Train Loss: 0.436, Acc: 84.98%\n",
      "Epoch [63] Test Loss: 0.530, Acc: 81.88%\n",
      "Epoch [64] Train Loss: 0.431, Acc: 85.17%\n",
      "Epoch [64] Test Loss: 0.540, Acc: 81.49%\n",
      "Epoch [65] Train Loss: 0.430, Acc: 85.24%\n",
      "Epoch [65] Test Loss: 0.564, Acc: 81.86%\n",
      "Epoch [66] Train Loss: 0.423, Acc: 85.42%\n",
      "Epoch [66] Test Loss: 0.579, Acc: 80.61%\n",
      "Epoch [67] Train Loss: 0.424, Acc: 85.37%\n",
      "Epoch [67] Test Loss: 0.515, Acc: 82.89%\n",
      "Epoch [68] Train Loss: 0.413, Acc: 85.74%\n",
      "Epoch [68] Test Loss: 0.549, Acc: 81.72%\n",
      "Epoch [69] Train Loss: 0.413, Acc: 85.89%\n",
      "Epoch [69] Test Loss: 0.534, Acc: 81.79%\n",
      "Epoch [70] Train Loss: 0.405, Acc: 85.95%\n",
      "Epoch [70] Test Loss: 0.518, Acc: 82.91%\n",
      "Epoch [71] Train Loss: 0.403, Acc: 86.12%\n",
      "Epoch [71] Test Loss: 0.517, Acc: 82.85%\n",
      "Epoch [72] Train Loss: 0.394, Acc: 86.30%\n",
      "Epoch [72] Test Loss: 0.518, Acc: 82.80%\n",
      "Epoch [73] Train Loss: 0.391, Acc: 86.45%\n",
      "Epoch [73] Test Loss: 0.519, Acc: 82.72%\n",
      "Epoch [74] Train Loss: 0.387, Acc: 86.83%\n",
      "Epoch [74] Test Loss: 0.533, Acc: 81.97%\n",
      "Epoch [75] Train Loss: 0.386, Acc: 86.57%\n",
      "Epoch [75] Test Loss: 0.519, Acc: 82.76%\n",
      "Epoch [76] Train Loss: 0.378, Acc: 86.73%\n",
      "Epoch [76] Test Loss: 0.505, Acc: 83.57%\n",
      "Epoch [77] Train Loss: 0.377, Acc: 86.99%\n",
      "Epoch [77] Test Loss: 0.514, Acc: 83.23%\n",
      "Epoch [78] Train Loss: 0.371, Acc: 87.23%\n",
      "Epoch [78] Test Loss: 0.532, Acc: 82.87%\n",
      "Epoch [79] Train Loss: 0.367, Acc: 87.38%\n",
      "Epoch [79] Test Loss: 0.501, Acc: 83.08%\n",
      "Epoch [80] Train Loss: 0.359, Acc: 87.56%\n",
      "Epoch [80] Test Loss: 0.510, Acc: 83.19%\n",
      "Epoch [81] Train Loss: 0.355, Acc: 87.69%\n",
      "Epoch [81] Test Loss: 0.503, Acc: 83.18%\n",
      "Epoch [82] Train Loss: 0.355, Acc: 87.92%\n",
      "Epoch [82] Test Loss: 0.515, Acc: 82.99%\n",
      "Epoch [83] Train Loss: 0.348, Acc: 88.01%\n",
      "Epoch [83] Test Loss: 0.560, Acc: 81.76%\n",
      "Epoch [84] Train Loss: 0.337, Acc: 88.32%\n",
      "Epoch [84] Test Loss: 0.521, Acc: 83.09%\n",
      "Epoch [85] Train Loss: 0.338, Acc: 88.25%\n",
      "Epoch [85] Test Loss: 0.520, Acc: 83.12%\n",
      "Epoch [86] Train Loss: 0.328, Acc: 88.55%\n",
      "Epoch [86] Test Loss: 0.470, Acc: 84.55%\n",
      "Epoch [87] Train Loss: 0.319, Acc: 88.97%\n",
      "Epoch [87] Test Loss: 0.545, Acc: 82.63%\n",
      "Epoch [88] Train Loss: 0.323, Acc: 88.78%\n",
      "Epoch [88] Test Loss: 0.497, Acc: 83.63%\n",
      "Epoch [89] Train Loss: 0.313, Acc: 89.18%\n",
      "Epoch [89] Test Loss: 0.527, Acc: 83.05%\n",
      "Epoch [90] Train Loss: 0.308, Acc: 89.27%\n",
      "Epoch [90] Test Loss: 0.476, Acc: 84.14%\n",
      "Epoch [91] Train Loss: 0.303, Acc: 89.59%\n",
      "Epoch [91] Test Loss: 0.462, Acc: 84.90%\n",
      "Epoch [92] Train Loss: 0.296, Acc: 89.65%\n",
      "Epoch [92] Test Loss: 0.479, Acc: 84.67%\n",
      "Epoch [93] Train Loss: 0.290, Acc: 89.79%\n",
      "Epoch [93] Test Loss: 0.470, Acc: 84.73%\n",
      "Epoch [94] Train Loss: 0.291, Acc: 89.97%\n",
      "Epoch [94] Test Loss: 0.513, Acc: 83.69%\n",
      "Epoch [95] Train Loss: 0.283, Acc: 90.09%\n",
      "Epoch [95] Test Loss: 0.476, Acc: 84.39%\n",
      "Epoch [96] Train Loss: 0.272, Acc: 90.56%\n",
      "Epoch [96] Test Loss: 0.480, Acc: 84.80%\n",
      "Epoch [97] Train Loss: 0.270, Acc: 90.64%\n",
      "Epoch [97] Test Loss: 0.486, Acc: 84.74%\n",
      "Epoch [98] Train Loss: 0.264, Acc: 90.94%\n",
      "Epoch [98] Test Loss: 0.473, Acc: 85.10%\n",
      "Epoch [99] Train Loss: 0.262, Acc: 90.90%\n",
      "Epoch [99] Test Loss: 0.497, Acc: 84.43%\n",
      "Epoch [100] Train Loss: 0.252, Acc: 91.16%\n",
      "Epoch [100] Test Loss: 0.475, Acc: 85.15%\n",
      "Epoch [101] Train Loss: 0.244, Acc: 91.37%\n",
      "Epoch [101] Test Loss: 0.470, Acc: 85.12%\n",
      "Epoch [102] Train Loss: 0.238, Acc: 91.78%\n",
      "Epoch [102] Test Loss: 0.462, Acc: 85.35%\n",
      "Epoch [103] Train Loss: 0.235, Acc: 91.81%\n",
      "Epoch [103] Test Loss: 0.452, Acc: 85.94%\n",
      "Epoch [104] Train Loss: 0.227, Acc: 92.09%\n",
      "Epoch [104] Test Loss: 0.458, Acc: 85.40%\n",
      "Epoch [105] Train Loss: 0.218, Acc: 92.46%\n",
      "Epoch [105] Test Loss: 0.468, Acc: 85.28%\n",
      "Epoch [106] Train Loss: 0.215, Acc: 92.40%\n",
      "Epoch [106] Test Loss: 0.466, Acc: 85.50%\n",
      "Epoch [107] Train Loss: 0.201, Acc: 92.94%\n",
      "Epoch [107] Test Loss: 0.500, Acc: 85.03%\n",
      "Epoch [108] Train Loss: 0.202, Acc: 92.87%\n",
      "Epoch [108] Test Loss: 0.468, Acc: 85.76%\n",
      "Epoch [109] Train Loss: 0.194, Acc: 93.20%\n",
      "Epoch [109] Test Loss: 0.471, Acc: 85.82%\n",
      "Epoch [110] Train Loss: 0.185, Acc: 93.51%\n",
      "Epoch [110] Test Loss: 0.442, Acc: 86.56%\n",
      "Epoch [111] Train Loss: 0.181, Acc: 93.63%\n",
      "Epoch [111] Test Loss: 0.456, Acc: 86.13%\n",
      "Epoch [112] Train Loss: 0.176, Acc: 93.86%\n",
      "Epoch [112] Test Loss: 0.434, Acc: 86.67%\n",
      "Epoch [113] Train Loss: 0.168, Acc: 94.20%\n",
      "Epoch [113] Test Loss: 0.451, Acc: 86.62%\n",
      "Epoch [114] Train Loss: 0.159, Acc: 94.36%\n",
      "Epoch [114] Test Loss: 0.456, Acc: 86.20%\n",
      "Epoch [115] Train Loss: 0.153, Acc: 94.68%\n",
      "Epoch [115] Test Loss: 0.441, Acc: 86.83%\n",
      "Epoch [116] Train Loss: 0.146, Acc: 94.96%\n",
      "Epoch [116] Test Loss: 0.445, Acc: 86.72%\n",
      "Epoch [117] Train Loss: 0.144, Acc: 95.02%\n",
      "Epoch [117] Test Loss: 0.468, Acc: 86.42%\n",
      "Epoch [118] Train Loss: 0.132, Acc: 95.28%\n",
      "Epoch [118] Test Loss: 0.447, Acc: 86.72%\n",
      "Epoch [119] Train Loss: 0.125, Acc: 95.70%\n",
      "Epoch [119] Test Loss: 0.440, Acc: 87.38%\n",
      "Epoch [120] Train Loss: 0.124, Acc: 95.73%\n",
      "Epoch [120] Test Loss: 0.456, Acc: 87.36%\n",
      "Epoch [121] Train Loss: 0.113, Acc: 96.06%\n",
      "Epoch [121] Test Loss: 0.448, Acc: 87.30%\n",
      "Epoch [122] Train Loss: 0.103, Acc: 96.47%\n",
      "Epoch [122] Test Loss: 0.435, Acc: 87.93%\n",
      "Epoch [123] Train Loss: 0.103, Acc: 96.47%\n",
      "Epoch [123] Test Loss: 0.462, Acc: 87.64%\n",
      "Epoch [124] Train Loss: 0.095, Acc: 96.64%\n",
      "Epoch [124] Test Loss: 0.455, Acc: 87.59%\n",
      "Epoch [125] Train Loss: 0.088, Acc: 96.97%\n",
      "Epoch [125] Test Loss: 0.440, Acc: 87.86%\n",
      "Epoch [126] Train Loss: 0.083, Acc: 97.16%\n",
      "Epoch [126] Test Loss: 0.453, Acc: 87.81%\n",
      "Epoch [127] Train Loss: 0.080, Acc: 97.31%\n",
      "Epoch [127] Test Loss: 0.451, Acc: 87.89%\n",
      "Epoch [128] Train Loss: 0.073, Acc: 97.53%\n",
      "Epoch [128] Test Loss: 0.448, Acc: 88.11%\n",
      "Epoch [129] Train Loss: 0.070, Acc: 97.68%\n",
      "Epoch [129] Test Loss: 0.457, Acc: 87.83%\n",
      "Epoch [130] Train Loss: 0.064, Acc: 97.84%\n",
      "Epoch [130] Test Loss: 0.450, Acc: 88.30%\n",
      "Epoch [131] Train Loss: 0.059, Acc: 97.98%\n",
      "Epoch [131] Test Loss: 0.458, Acc: 88.25%\n",
      "Epoch [132] Train Loss: 0.055, Acc: 98.10%\n",
      "Epoch [132] Test Loss: 0.442, Acc: 88.50%\n",
      "Epoch [133] Train Loss: 0.049, Acc: 98.30%\n",
      "Epoch [133] Test Loss: 0.458, Acc: 88.51%\n",
      "Epoch [134] Train Loss: 0.047, Acc: 98.49%\n",
      "Epoch [134] Test Loss: 0.451, Acc: 88.58%\n",
      "Epoch [135] Train Loss: 0.045, Acc: 98.59%\n",
      "Epoch [135] Test Loss: 0.453, Acc: 88.46%\n",
      "Epoch [136] Train Loss: 0.043, Acc: 98.60%\n",
      "Epoch [136] Test Loss: 0.456, Acc: 88.46%\n",
      "Epoch [137] Train Loss: 0.040, Acc: 98.70%\n",
      "Epoch [137] Test Loss: 0.444, Acc: 88.93%\n",
      "Epoch [138] Train Loss: 0.037, Acc: 98.82%\n",
      "Epoch [138] Test Loss: 0.448, Acc: 88.64%\n",
      "Epoch [139] Train Loss: 0.034, Acc: 98.90%\n",
      "Epoch [139] Test Loss: 0.453, Acc: 88.79%\n",
      "Epoch [140] Train Loss: 0.033, Acc: 98.91%\n",
      "Epoch [140] Test Loss: 0.450, Acc: 88.97%\n",
      "Epoch [141] Train Loss: 0.032, Acc: 99.02%\n",
      "Epoch [141] Test Loss: 0.454, Acc: 88.74%\n",
      "Epoch [142] Train Loss: 0.031, Acc: 99.01%\n",
      "Epoch [142] Test Loss: 0.451, Acc: 88.98%\n",
      "Epoch [143] Train Loss: 0.029, Acc: 99.06%\n",
      "Epoch [143] Test Loss: 0.454, Acc: 89.14%\n",
      "Epoch [144] Train Loss: 0.029, Acc: 99.13%\n",
      "Epoch [144] Test Loss: 0.453, Acc: 88.93%\n",
      "Epoch [145] Train Loss: 0.028, Acc: 99.16%\n",
      "Epoch [145] Test Loss: 0.450, Acc: 89.01%\n",
      "Epoch [146] Train Loss: 0.027, Acc: 99.18%\n",
      "Epoch [146] Test Loss: 0.454, Acc: 89.08%\n",
      "Epoch [147] Train Loss: 0.027, Acc: 99.18%\n",
      "Epoch [147] Test Loss: 0.451, Acc: 89.02%\n",
      "Epoch [148] Train Loss: 0.028, Acc: 99.10%\n",
      "Epoch [148] Test Loss: 0.454, Acc: 89.00%\n",
      "Epoch [149] Train Loss: 0.027, Acc: 99.19%\n",
      "Epoch [149] Test Loss: 0.451, Acc: 89.01%\n",
      "Epoch [150] Train Loss: 0.025, Acc: 99.28%\n",
      "Epoch [150] Test Loss: 0.451, Acc: 88.99%\n",
      "Epoch [151] Train Loss: 0.029, Acc: 99.16%\n",
      "Epoch [151] Test Loss: 0.452, Acc: 89.05%\n",
      "Epoch [152] Train Loss: 0.027, Acc: 99.15%\n",
      "Epoch [152] Test Loss: 0.451, Acc: 89.01%\n",
      "Epoch [153] Train Loss: 0.026, Acc: 99.25%\n",
      "Epoch [153] Test Loss: 0.453, Acc: 89.09%\n",
      "Epoch [154] Train Loss: 0.026, Acc: 99.21%\n",
      "Epoch [154] Test Loss: 0.453, Acc: 89.07%\n",
      "Epoch [155] Train Loss: 0.027, Acc: 99.15%\n",
      "Epoch [155] Test Loss: 0.451, Acc: 89.08%\n",
      "Epoch [156] Train Loss: 0.026, Acc: 99.16%\n",
      "Epoch [156] Test Loss: 0.449, Acc: 89.10%\n",
      "Epoch [157] Train Loss: 0.027, Acc: 99.16%\n",
      "Epoch [157] Test Loss: 0.452, Acc: 89.02%\n",
      "Epoch [158] Train Loss: 0.027, Acc: 99.22%\n",
      "Epoch [158] Test Loss: 0.455, Acc: 89.06%\n",
      "Epoch [159] Train Loss: 0.026, Acc: 99.26%\n",
      "Epoch [159] Test Loss: 0.457, Acc: 89.01%\n",
      "Epoch [160] Train Loss: 0.026, Acc: 99.20%\n",
      "Epoch [160] Test Loss: 0.455, Acc: 89.19%\n",
      "Epoch [161] Train Loss: 0.027, Acc: 99.13%\n",
      "Epoch [161] Test Loss: 0.460, Acc: 89.03%\n",
      "Epoch [162] Train Loss: 0.027, Acc: 99.15%\n",
      "Epoch [162] Test Loss: 0.460, Acc: 89.03%\n",
      "Epoch [163] Train Loss: 0.029, Acc: 99.05%\n",
      "Epoch [163] Test Loss: 0.463, Acc: 88.93%\n",
      "Epoch [164] Train Loss: 0.027, Acc: 99.18%\n",
      "Epoch [164] Test Loss: 0.473, Acc: 88.86%\n",
      "Epoch [165] Train Loss: 0.029, Acc: 99.04%\n",
      "Epoch [165] Test Loss: 0.475, Acc: 88.97%\n",
      "Epoch [166] Train Loss: 0.030, Acc: 99.06%\n",
      "Epoch [166] Test Loss: 0.478, Acc: 88.69%\n",
      "Epoch [167] Train Loss: 0.031, Acc: 99.01%\n",
      "Epoch [167] Test Loss: 0.485, Acc: 88.58%\n",
      "Epoch [168] Train Loss: 0.036, Acc: 98.80%\n",
      "Epoch [168] Test Loss: 0.483, Acc: 88.48%\n",
      "Epoch [169] Train Loss: 0.037, Acc: 98.76%\n",
      "Epoch [169] Test Loss: 0.493, Acc: 88.47%\n",
      "Epoch [170] Train Loss: 0.038, Acc: 98.74%\n",
      "Epoch [170] Test Loss: 0.506, Acc: 88.00%\n",
      "Epoch [171] Train Loss: 0.045, Acc: 98.46%\n",
      "Epoch [171] Test Loss: 0.496, Acc: 88.24%\n",
      "Epoch [172] Train Loss: 0.050, Acc: 98.27%\n",
      "Epoch [172] Test Loss: 0.498, Acc: 88.05%\n",
      "Epoch [173] Train Loss: 0.057, Acc: 98.11%\n",
      "Epoch [173] Test Loss: 0.504, Acc: 87.66%\n",
      "Epoch [174] Train Loss: 0.063, Acc: 97.82%\n",
      "Epoch [174] Test Loss: 0.512, Acc: 87.54%\n",
      "Epoch [175] Train Loss: 0.069, Acc: 97.66%\n",
      "Epoch [175] Test Loss: 0.529, Acc: 86.76%\n",
      "Epoch [176] Train Loss: 0.081, Acc: 97.15%\n",
      "Epoch [176] Test Loss: 0.529, Acc: 86.80%\n",
      "Epoch [177] Train Loss: 0.094, Acc: 96.71%\n",
      "Epoch [177] Test Loss: 0.498, Acc: 86.97%\n",
      "Epoch [178] Train Loss: 0.097, Acc: 96.58%\n",
      "Epoch [178] Test Loss: 0.506, Acc: 87.22%\n",
      "Epoch [179] Train Loss: 0.109, Acc: 96.16%\n",
      "Epoch [179] Test Loss: 0.499, Acc: 86.75%\n",
      "Epoch [180] Train Loss: 0.116, Acc: 95.95%\n",
      "Epoch [180] Test Loss: 0.536, Acc: 85.69%\n",
      "Epoch [181] Train Loss: 0.135, Acc: 95.28%\n",
      "Epoch [181] Test Loss: 0.503, Acc: 86.25%\n",
      "Epoch [182] Train Loss: 0.137, Acc: 95.21%\n",
      "Epoch [182] Test Loss: 0.511, Acc: 85.80%\n",
      "Epoch [183] Train Loss: 0.148, Acc: 94.77%\n",
      "Epoch [183] Test Loss: 0.496, Acc: 86.12%\n",
      "Epoch [184] Train Loss: 0.156, Acc: 94.44%\n",
      "Epoch [184] Test Loss: 0.505, Acc: 85.95%\n",
      "Epoch [185] Train Loss: 0.162, Acc: 94.26%\n",
      "Epoch [185] Test Loss: 0.491, Acc: 86.07%\n",
      "Epoch [186] Train Loss: 0.173, Acc: 93.95%\n",
      "Epoch [186] Test Loss: 0.513, Acc: 85.13%\n",
      "Epoch [187] Train Loss: 0.183, Acc: 93.55%\n",
      "Epoch [187] Test Loss: 0.486, Acc: 85.58%\n",
      "Epoch [188] Train Loss: 0.187, Acc: 93.48%\n",
      "Epoch [188] Test Loss: 0.494, Acc: 85.55%\n",
      "Epoch [189] Train Loss: 0.200, Acc: 93.02%\n",
      "Epoch [189] Test Loss: 0.501, Acc: 85.32%\n",
      "Epoch [190] Train Loss: 0.205, Acc: 92.90%\n",
      "Epoch [190] Test Loss: 0.486, Acc: 85.02%\n",
      "Epoch [191] Train Loss: 0.210, Acc: 92.56%\n",
      "Epoch [191] Test Loss: 0.518, Acc: 84.76%\n",
      "Epoch [192] Train Loss: 0.213, Acc: 92.46%\n",
      "Epoch [192] Test Loss: 0.499, Acc: 85.19%\n",
      "Epoch [193] Train Loss: 0.224, Acc: 92.15%\n",
      "Epoch [193] Test Loss: 0.516, Acc: 84.81%\n",
      "Epoch [194] Train Loss: 0.230, Acc: 91.94%\n",
      "Epoch [194] Test Loss: 0.554, Acc: 83.84%\n",
      "Epoch [195] Train Loss: 0.238, Acc: 91.47%\n",
      "Epoch [195] Test Loss: 0.503, Acc: 84.91%\n",
      "Epoch [196] Train Loss: 0.238, Acc: 91.55%\n",
      "Epoch [196] Test Loss: 0.552, Acc: 82.90%\n",
      "Epoch [197] Train Loss: 0.246, Acc: 91.27%\n",
      "Epoch [197] Test Loss: 0.501, Acc: 84.66%\n",
      "Epoch [198] Train Loss: 0.248, Acc: 91.32%\n",
      "Epoch [198] Test Loss: 0.524, Acc: 83.70%\n",
      "Epoch [199] Train Loss: 0.260, Acc: 91.04%\n",
      "Epoch [199] Test Loss: 0.504, Acc: 84.44%\n",
      "Epoch [200] Train Loss: 0.259, Acc: 90.99%\n",
      "Epoch [200] Test Loss: 0.530, Acc: 83.60%\n",
      "Training finished. Best Test Accuracy: 89.19%\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 5. 訓練迴圈\n",
    "# -------------------------\n",
    "best_acc = 0\n",
    "num_epochs = 200  # 建議 50~200，看時間長度\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train(epoch)\n",
    "    acc = test(epoch)\n",
    "    scheduler.step()\n",
    "\n",
    "    # 儲存最佳模型\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), \"best_resnet18.pth\")\n",
    "\n",
    "print(\"Training finished. Best Test Accuracy: {:.2f}%\".format(best_acc))\n",
    "\n",
    "'''\n",
    "Epoch [200] Train Loss: 0.259, Acc: 90.99%\n",
    "Epoch [200] Test Loss: 0.530, Acc: 83.60%\n",
    "Training finished. Best Test Accuracy: 89.19%\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
