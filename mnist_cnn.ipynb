{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d769498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 60000\n",
      "Test dataset size: 10000\n",
      "MNIST dataset downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Import MNIST\n",
    "from torchvision import datasets\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# Define the path to save the dataset\n",
    "data_path = 'data'\n",
    "# Download the MNIST dataset\n",
    "mnist_train = MNIST(root=data_path, train=True, download=True) #建立訓練資料集\n",
    "mnist_test = MNIST(root=data_path, train=False, download=True) #建立測試資料集\n",
    "# Print the size of the training and test datasets\n",
    "print(f\"Training dataset size: {len(mnist_train)}\")\n",
    "print(f\"Test dataset size: {len(mnist_test)}\")\n",
    "print(\"MNIST dataset downloaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a277eaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the first image and label\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "idx = random.randint(0, len(mnist_train) - 1)\n",
    "plt.imshow(mnist_train.data[idx], cmap='gray')\n",
    "plt.title(f\"Label: {mnist_train.targets[idx]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd4104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),  # 28x28 -> 28x28\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),  # 28x28 -> 14x14\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # 14x14 -> 14x14\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),  # 14x14 -> 7x7\n",
    "            torch.nn.Flatten(), #攤平變成一維\n",
    "            torch.nn.Linear(64 * 7 * 7, 128), #輸入維度64*7*7，輸出維度128\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        return out\n",
    "\n",
    "# CNN = torch.jit.script(CNN())\n",
    "# 50epoch 96.75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e39f31ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32]) tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "torch.Size([32]) tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "torch.Size([32]) tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "torch.Size([4]) tensor([96, 97, 98, 99])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "test = torch.tensor(list(range(100)))\n",
    "test_dataset = TensorDataset(test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "for batch, in test_loader:\n",
    "    print(batch.shape, batch)\n",
    "\n",
    "# for idx in range(0, len(test), 32):\n",
    "#     batch = test[idx:idx+32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a311687d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0., 10.])\n",
      "tensor([4.5398e-05, 9.9995e-01])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([4.5398e-05, 9.9995e-01])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = torch.tensor([0, 10.0])\n",
    "print(Y)\n",
    "print(torch.softmax(Y, dim=0))\n",
    "\n",
    "torch.exp(Y)/torch.sum(torch.exp(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2324633f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 28, 28]) torch.Size([60000])\n",
      "torch.Size([10000, 1, 28, 28]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "train_X = mnist_train.data.view(60000, 1, 28, 28).float() / 255.0\n",
    "train_y = mnist_train.targets\n",
    "test_X = mnist_test.data.view(10000, 1, 28, 28).float() / 255.0\n",
    "test_y = mnist_test.targets\n",
    "# dataloader\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(train_X, train_y)\n",
    "test_dataset = TensorDataset(test_X, test_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "print(train_X.shape, train_y.shape)\n",
    "print(test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f745413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "torch.Size([64, 32, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 25088])\n"
     ]
    }
   ],
   "source": [
    "for batch_X, batch_y in train_loader:\n",
    "    print(batch_X.shape, batch_y.shape)\n",
    "    print(torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)(batch_X).shape)\n",
    "    print(torch.nn.Flatten()(batch_X).shape)\n",
    "    print(torch.nn.Flatten()(torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)(batch_X)).shape)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43accefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:30<00:00, 30.75it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 74.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  1/100], Train Loss: 0.5503, Accuracy: 0.8629 Val Loss: 0.1980, Val Accuracy: 0.9418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:31<00:00, 29.56it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  2/100], Train Loss: 0.1649, Accuracy: 0.9518 Val Loss: 0.1129, Val Accuracy: 0.9666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:33<00:00, 27.69it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 74.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  3/100], Train Loss: 0.1085, Accuracy: 0.9681 Val Loss: 0.0840, Val Accuracy: 0.9744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:32<00:00, 28.55it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 74.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  4/100], Train Loss: 0.0822, Accuracy: 0.9751 Val Loss: 0.0655, Val Accuracy: 0.9781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:33<00:00, 28.18it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  5/100], Train Loss: 0.0680, Accuracy: 0.9797 Val Loss: 0.0563, Val Accuracy: 0.9816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:38<00:00, 24.63it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  6/100], Train Loss: 0.0581, Accuracy: 0.9832 Val Loss: 0.0529, Val Accuracy: 0.9819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:33<00:00, 28.26it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 76.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  7/100], Train Loss: 0.0513, Accuracy: 0.9849 Val Loss: 0.0458, Val Accuracy: 0.9846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:32<00:00, 28.56it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  8/100], Train Loss: 0.0452, Accuracy: 0.9866 Val Loss: 0.0402, Val Accuracy: 0.9867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:39<00:00, 23.65it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 65.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  9/100], Train Loss: 0.0408, Accuracy: 0.9880 Val Loss: 0.0409, Val Accuracy: 0.9849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:40<00:00, 23.21it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 10/100], Train Loss: 0.0372, Accuracy: 0.9889 Val Loss: 0.0378, Val Accuracy: 0.9870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:35<00:00, 26.14it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 75.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 11/100], Train Loss: 0.0340, Accuracy: 0.9898 Val Loss: 0.0421, Val Accuracy: 0.9862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 450/938 [00:17<00:18, 26.33it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# Train the model\n",
    "model = CNN()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(50):\n",
    "    total_loss = 0.0\n",
    "    total_hit = 0\n",
    "    for batch_X, batch_y in tqdm(train_loader, total=len(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        # print(batch_X.shape, batch_y.shape)\n",
    "        # torch.Size([64, 784]) torch.Size([64])\n",
    "        outputs = model(batch_X)\n",
    "        # print(outputs.shape, batch_y.shape)\n",
    "        # torch.Size([64, 10]) torch.Size([64])\n",
    "        \n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        total_hit += torch.sum(batch_y == torch.argmax(outputs, dim=1)).item()\n",
    "    train_loss = total_loss / len(train_loader)\n",
    "    train_accuracy = total_hit / len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    total_loss = 0.0\n",
    "    total_hit = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in tqdm(test_loader, total=len(test_loader)):\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_loss += loss.item()\n",
    "            total_hit += torch.sum(batch_y == torch.argmax(outputs, dim=1)).item()\n",
    "    test_loss = total_loss / len(test_loader)\n",
    "    test_accuracy = total_hit / len(test_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1:3d}/100], Train Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f} Val Loss: {test_loss:.4f}, Val Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc1a96b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 7, 9, 6, 9, 8, 3, 7, 0, 7, 5, 5, 2, 9, 9, 3, 5, 5, 1, 0, 0, 0, 8, 8,\n",
      "        2, 8, 0, 0, 9, 0, 0, 2, 4, 8, 3, 9, 9, 1, 7, 0, 0, 2, 8, 5, 1, 7, 2, 0,\n",
      "        1, 0, 0, 4, 6, 2, 5, 0, 2, 5, 6, 6, 5, 1, 9, 6])\n",
      "tensor([1, 7, 7, 6, 9, 8, 3, 7, 0, 7, 8, 0, 2, 9, 9, 3, 5, 5, 1, 3, 0, 0, 8, 8,\n",
      "        2, 8, 0, 0, 7, 0, 0, 2, 4, 8, 3, 9, 9, 1, 7, 0, 0, 2, 8, 1, 1, 7, 0, 8,\n",
      "        1, 0, 0, 4, 6, 2, 5, 0, 2, 5, 6, 6, 8, 1, 4, 6])\n",
      "tensor(0.8438)\n"
     ]
    }
   ],
   "source": [
    "pred_Y = torch.argmax(outputs, dim=1)\n",
    "print(pred_Y)\n",
    "print(batch_y)\n",
    "\n",
    "print(torch.sum(batch_y == pred_Y) / len(batch_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
