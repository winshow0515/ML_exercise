{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1ce4374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b735ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料預處理\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),   # 隨機裁切 (增強泛化能力)\n",
    "    transforms.RandomHorizontalFlip(),      # 隨機水平翻轉\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010))  # 正規化 (CIFAR-10 常用均值/方差)\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d498da17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 模型\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = torchvision.models.resnet18(num_classes=10)  # CIFAR-10 10 類\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83caa387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss, Optimizer, Scheduler\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)  # 200 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c3f01a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練 & 測試函數\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    total, correct, running_loss = 0, 0, 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    acc = 100.*correct/total\n",
    "    print(f\"Epoch [{epoch}] Train Loss: {running_loss/len(train_loader):.3f}, Acc: {acc:.2f}%\")\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    total, correct, test_loss = 0, 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    acc = 100.*correct/total\n",
    "    print(f\"Epoch [{epoch}] Test Loss: {test_loss/len(test_loader):.3f}, Acc: {acc:.2f}%\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "889ed86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] Train Loss: 2.153, Acc: 30.05%\n",
      "Epoch [1] Test Loss: 1.581, Acc: 41.21%\n",
      "Epoch [2] Train Loss: 1.500, Acc: 45.08%\n",
      "Epoch [2] Test Loss: 1.325, Acc: 50.70%\n",
      "Epoch [3] Train Loss: 1.315, Acc: 52.49%\n",
      "Epoch [3] Test Loss: 1.195, Acc: 56.64%\n",
      "Epoch [4] Train Loss: 1.169, Acc: 58.14%\n",
      "Epoch [4] Test Loss: 1.020, Acc: 63.56%\n",
      "Epoch [5] Train Loss: 1.067, Acc: 62.27%\n",
      "Epoch [5] Test Loss: 1.005, Acc: 64.46%\n",
      "Epoch [6] Train Loss: 0.992, Acc: 65.05%\n",
      "Epoch [6] Test Loss: 0.993, Acc: 65.40%\n",
      "Epoch [7] Train Loss: 0.943, Acc: 66.87%\n",
      "Epoch [7] Test Loss: 0.956, Acc: 67.78%\n",
      "Epoch [8] Train Loss: 0.910, Acc: 68.33%\n",
      "Epoch [8] Test Loss: 1.031, Acc: 64.86%\n",
      "Epoch [9] Train Loss: 0.867, Acc: 69.93%\n",
      "Epoch [9] Test Loss: 0.864, Acc: 70.79%\n",
      "Epoch [10] Train Loss: 0.844, Acc: 70.80%\n",
      "Epoch [10] Test Loss: 0.801, Acc: 72.45%\n",
      "Epoch [11] Train Loss: 0.822, Acc: 71.51%\n",
      "Epoch [11] Test Loss: 0.860, Acc: 71.32%\n",
      "Epoch [12] Train Loss: 0.809, Acc: 71.94%\n",
      "Epoch [12] Test Loss: 0.878, Acc: 70.78%\n",
      "Epoch [13] Train Loss: 0.784, Acc: 72.98%\n",
      "Epoch [13] Test Loss: 0.887, Acc: 70.22%\n",
      "Epoch [14] Train Loss: 0.778, Acc: 73.23%\n",
      "Epoch [14] Test Loss: 0.896, Acc: 70.17%\n",
      "Epoch [15] Train Loss: 0.762, Acc: 73.57%\n",
      "Epoch [15] Test Loss: 0.743, Acc: 74.65%\n",
      "Epoch [16] Train Loss: 0.755, Acc: 73.93%\n",
      "Epoch [16] Test Loss: 0.868, Acc: 70.99%\n",
      "Epoch [17] Train Loss: 0.746, Acc: 74.39%\n",
      "Epoch [17] Test Loss: 0.801, Acc: 72.66%\n",
      "Epoch [18] Train Loss: 0.739, Acc: 74.53%\n",
      "Epoch [18] Test Loss: 0.776, Acc: 73.62%\n",
      "Epoch [19] Train Loss: 0.730, Acc: 75.00%\n",
      "Epoch [19] Test Loss: 0.761, Acc: 73.82%\n",
      "Epoch [20] Train Loss: 0.715, Acc: 75.44%\n",
      "Epoch [20] Test Loss: 0.754, Acc: 74.14%\n",
      "Epoch [21] Train Loss: 0.717, Acc: 75.32%\n",
      "Epoch [21] Test Loss: 0.803, Acc: 72.30%\n",
      "Epoch [22] Train Loss: 0.710, Acc: 75.55%\n",
      "Epoch [22] Test Loss: 0.722, Acc: 75.71%\n",
      "Epoch [23] Train Loss: 0.708, Acc: 75.68%\n",
      "Epoch [23] Test Loss: 0.784, Acc: 73.26%\n",
      "Epoch [24] Train Loss: 0.701, Acc: 75.94%\n",
      "Epoch [24] Test Loss: 0.738, Acc: 75.13%\n",
      "Epoch [25] Train Loss: 0.694, Acc: 76.12%\n",
      "Epoch [25] Test Loss: 0.891, Acc: 69.82%\n",
      "Epoch [26] Train Loss: 0.688, Acc: 76.40%\n",
      "Epoch [26] Test Loss: 0.861, Acc: 71.50%\n",
      "Epoch [27] Train Loss: 0.690, Acc: 76.17%\n",
      "Epoch [27] Test Loss: 0.778, Acc: 74.10%\n",
      "Epoch [28] Train Loss: 0.681, Acc: 76.69%\n",
      "Epoch [28] Test Loss: 0.815, Acc: 72.77%\n",
      "Epoch [29] Train Loss: 0.675, Acc: 76.84%\n",
      "Epoch [29] Test Loss: 0.773, Acc: 74.10%\n",
      "Epoch [30] Train Loss: 0.675, Acc: 76.90%\n",
      "Epoch [30] Test Loss: 0.710, Acc: 75.82%\n",
      "Epoch [31] Train Loss: 0.672, Acc: 76.93%\n",
      "Epoch [31] Test Loss: 0.799, Acc: 73.57%\n",
      "Epoch [32] Train Loss: 0.672, Acc: 76.89%\n",
      "Epoch [32] Test Loss: 0.756, Acc: 73.85%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m num_epochs = \u001b[32m200\u001b[39m  \u001b[38;5;66;03m# 建議 50~200，看時間長度\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, num_epochs+\u001b[32m1\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     acc = test(epoch)\n\u001b[32m      9\u001b[39m     scheduler.step()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(epoch)\u001b[39m\n\u001b[32m      3\u001b[39m model.train()\n\u001b[32m      4\u001b[39m total, correct, running_loss = \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0.0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (images, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m      6\u001b[39m     images, labels = images.to(device), labels.to(device)\n\u001b[32m      8\u001b[39m     optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\winsh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:494\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\winsh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:427\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    426\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\winsh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1172\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1165\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1166\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1169\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1170\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1171\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1172\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n\u001b[32m   1174\u001b[39m \u001b[38;5;28mself\u001b[39m._workers.append(w)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\winsh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\winsh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\winsh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\context.py:337\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_win32\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\winsh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\popen_spawn_win32.py:97\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     96\u001b[39m     reduction.dump(prep_data, to_child)\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[43mreduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     99\u001b[39m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\winsh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\reduction.py:60\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, file, protocol)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdump\u001b[39m(obj, file, protocol=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     59\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 訓練迴圈\n",
    "\n",
    "best_acc = 0\n",
    "num_epochs = 200  # 建議 50~200，看時間長度\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train(epoch)\n",
    "    acc = test(epoch)\n",
    "    scheduler.step()\n",
    "\n",
    "    # 儲存最佳模型\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), \"best_resnet18.pth\")\n",
    "\n",
    "print(\"Training finished. Best Test Accuracy: {:.2f}%\".format(best_acc))\n",
    "\n",
    "'''\n",
    "最佳結果，準確率約89.19%（200 epochs）\n",
    "Epoch [200] Train Loss: 0.259, Acc: 90.99%\n",
    "Epoch [200] Test Loss: 0.530, Acc: 83.60%\n",
    "Training finished. Best Test Accuracy: 89.19%\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
