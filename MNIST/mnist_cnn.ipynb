{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d769498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 60000\n",
      "Test dataset size: 10000\n",
      "MNIST dataset downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Import MNIST\n",
    "from torchvision import datasets\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# Define the path to save the dataset\n",
    "data_path = 'data'\n",
    "# Download the MNIST dataset\n",
    "mnist_train = MNIST(root=data_path, train=True, download=True) #建立訓練資料集\n",
    "mnist_test = MNIST(root=data_path, train=False, download=True) #建立測試資料集\n",
    "# Print the size of the training and test datasets\n",
    "print(f\"Training dataset size: {len(mnist_train)}\")\n",
    "print(f\"Test dataset size: {len(mnist_test)}\")\n",
    "print(\"MNIST dataset downloaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a277eaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the first image and label\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "idx = random.randint(0, len(mnist_train) - 1)\n",
    "plt.imshow(mnist_train.data[idx], cmap='gray')\n",
    "plt.title(f\"Label: {mnist_train.targets[idx]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cd4104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),  # 28x28 -> 28x28\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),  # 28x28 -> 14x14\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # 14x14 -> 14x14\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),  # 14x14 -> 7x7\n",
    "            torch.nn.Flatten(), #攤平變成一維\n",
    "            torch.nn.Linear(64 * 7 * 7, 128), #輸入維度64*7*7，輸出維度128\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        return out\n",
    "\n",
    "# CNN = torch.jit.script(CNN())\n",
    "# 50epoch 96.75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e39f31ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32]) tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "torch.Size([32]) tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "torch.Size([32]) tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n",
      "torch.Size([4]) tensor([96, 97, 98, 99])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "test = torch.tensor(list(range(100)))\n",
    "test_dataset = TensorDataset(test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "for batch, in test_loader:\n",
    "    print(batch.shape, batch)\n",
    "\n",
    "# for idx in range(0, len(test), 32):\n",
    "#     batch = test[idx:idx+32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a311687d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0., 10.])\n",
      "tensor([4.5398e-05, 9.9995e-01])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([4.5398e-05, 9.9995e-01])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = torch.tensor([0, 10.0])\n",
    "print(Y)\n",
    "print(torch.softmax(Y, dim=0))\n",
    "\n",
    "torch.exp(Y)/torch.sum(torch.exp(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2324633f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 28, 28]) torch.Size([60000])\n",
      "torch.Size([10000, 1, 28, 28]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "train_X = mnist_train.data.view(60000, 1, 28, 28).float() / 255.0\n",
    "train_y = mnist_train.targets\n",
    "test_X = mnist_test.data.view(10000, 1, 28, 28).float() / 255.0\n",
    "test_y = mnist_test.targets\n",
    "# dataloader\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(train_X, train_y)\n",
    "test_dataset = TensorDataset(test_X, test_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "print(train_X.shape, train_y.shape)\n",
    "print(test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f745413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "torch.Size([64, 32, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 25088])\n"
     ]
    }
   ],
   "source": [
    "for batch_X, batch_y in train_loader:\n",
    "    print(batch_X.shape, batch_y.shape)\n",
    "    print(torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)(batch_X).shape)\n",
    "    print(torch.nn.Flatten()(batch_X).shape)\n",
    "    print(torch.nn.Flatten()(torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)(batch_X)).shape)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43accefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 644/938 [00:10<00:04, 63.86it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m loss = criterion(outputs, batch_y)\n\u001b[32m     20\u001b[39m loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m total_loss += loss.item()\n\u001b[32m     23\u001b[39m total_hit += torch.sum(batch_y == torch.argmax(outputs, dim=\u001b[32m1\u001b[39m)).item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\winsh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\optim\\optimizer.py:516\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    511\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    512\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    513\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    519\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\winsh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\optim\\optimizer.py:81\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     80\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     83\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\winsh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\optim\\adam.py:247\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    235\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    237\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    238\u001b[39m         group,\n\u001b[32m    239\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m         state_steps,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\winsh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\optim\\optimizer.py:149\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\winsh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\optim\\adam.py:949\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    946\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    947\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\winsh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\optim\\adam.py:533\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    531\u001b[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m533\u001b[39m         denom = \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m     param.addcdiv_(exp_avg, denom, value=-step_size)\n\u001b[32m    537\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# Train the model\n",
    "model = CNN()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(50):\n",
    "    total_loss = 0.0\n",
    "    total_hit = 0\n",
    "    for batch_X, batch_y in tqdm(train_loader, total=len(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        # print(batch_X.shape, batch_y.shape)\n",
    "        # torch.Size([64, 784]) torch.Size([64])\n",
    "        outputs = model(batch_X)\n",
    "        # print(outputs.shape, batch_y.shape)\n",
    "        # torch.Size([64, 10]) torch.Size([64])\n",
    "        \n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        total_hit += torch.sum(batch_y == torch.argmax(outputs, dim=1)).item()\n",
    "    train_loss = total_loss / len(train_loader)\n",
    "    train_accuracy = total_hit / len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    total_loss = 0.0\n",
    "    total_hit = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in tqdm(test_loader, total=len(test_loader)):\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_loss += loss.item()\n",
    "            total_hit += torch.sum(batch_y == torch.argmax(outputs, dim=1)).item()\n",
    "    test_loss = total_loss / len(test_loader)\n",
    "    test_accuracy = total_hit / len(test_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1:3d}/100], Train Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f} Val Loss: {test_loss:.4f}, Val Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc1a96b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 7, 9, 6, 9, 8, 3, 7, 0, 7, 5, 5, 2, 9, 9, 3, 5, 5, 1, 0, 0, 0, 8, 8,\n",
      "        2, 8, 0, 0, 9, 0, 0, 2, 4, 8, 3, 9, 9, 1, 7, 0, 0, 2, 8, 5, 1, 7, 2, 0,\n",
      "        1, 0, 0, 4, 6, 2, 5, 0, 2, 5, 6, 6, 5, 1, 9, 6])\n",
      "tensor([1, 7, 7, 6, 9, 8, 3, 7, 0, 7, 8, 0, 2, 9, 9, 3, 5, 5, 1, 3, 0, 0, 8, 8,\n",
      "        2, 8, 0, 0, 7, 0, 0, 2, 4, 8, 3, 9, 9, 1, 7, 0, 0, 2, 8, 1, 1, 7, 0, 8,\n",
      "        1, 0, 0, 4, 6, 2, 5, 0, 2, 5, 6, 6, 8, 1, 4, 6])\n",
      "tensor(0.8438)\n"
     ]
    }
   ],
   "source": [
    "pred_Y = torch.argmax(outputs, dim=1)\n",
    "print(pred_Y)\n",
    "print(batch_y)\n",
    "\n",
    "print(torch.sum(batch_y == pred_Y) / len(batch_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
